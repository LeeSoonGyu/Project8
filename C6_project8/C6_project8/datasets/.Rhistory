# 라이브러리
#install.packages("tree")
library(tree)
#install.packages("doBy")
library(doBy)
#install.packages("party")
library(party) #ls("package:party")
#install.packages("caret")
library(caret) #ls("package:caret")
#install.packages("dplyr")
library(dplyr)
#install.packages("e1071") #나이브 베이즈
library(e1071)
#install.packages("randomForest")
library(randomForest)
#install.packages("data.table")
library(data.table)
#install.packages("xgboost")
library(xgboost)
#install.packages("plyr")
library(plyr)
#install.packages("car")#vif 공분산분석
library(car)
#install.packages("kernlab")
library(kernlab)
#install.packages("class")
library(class)
#install.packages("nnet")
library(nnet)
#install.packages('adabag')
library(adabag)
#install.packages('pROC')
library(pROC)
#install.packages("MASS") #ROC 커브
library(MASS)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("pls") #시계열분석
library(pls)
# 1)데이터 불러오기
spam <- read.csv('spam.csv', header = T)
str(spam)
set.seed(9999)
# 2)데이터 정규화
normalize <- function(x) {
return ((x-min(x))/(max(x)-min(x)))
}
spam[56:57] <- normalize(spam[56:57])
# 3) train/test sets 생성
#(1)doBy train/test sets 생성
spam_train_doBy <- sampleBy(~spam, frac = 0.7, data = spam)
enrow <- rownames(spam_train_doBy)
nurow <- as.numeric(gsub('\\D','',enrow))
spam_test_doBy <- spam[-nurow,]
#(2)caret train/test sets 생성
set.seed(8888)
train_idx <- createDataPartition(spam$spam, p=0.7, list=F)
spam_train_caret <- spam[train_idx,]
spam_train_label_caret <- spam$spam[train_idx]
spam_test_caret <- spam[-train_idx,]
#(4)모델 성능 평가 지표(정확도 확인)
confusionMatrix(spam_nb_pred_doby, as.factor(spam_test_doBy$spam))
## e1071 패키지의 나이브베이즈는 약 72%의 정확도로 분류
knitr::opts_chunk$set(echo = TRUE)
setwd('C:/Users/junseo/OneDrive/code/Project/project8/datasets')
options(max.print = 300)
# 라이브러리
#install.packages("tree")
library(tree)
#install.packages("doBy")
library(doBy)
#install.packages("party")
library(party) #ls("package:party")
#install.packages("caret")
library(caret) #ls("package:caret")
#install.packages("dplyr")
library(dplyr)
#install.packages("e1071") #나이브 베이즈
library(e1071)
#install.packages("randomForest")
library(randomForest)
#install.packages("data.table")
library(data.table)
#install.packages("xgboost")
library(xgboost)
#install.packages("plyr")
library(plyr)
#install.packages("car")#vif 공분산분석
library(car)
#install.packages("kernlab")
library(kernlab)
#install.packages("class")
library(class)
#install.packages("nnet")
library(nnet)
#install.packages('adabag')
library(adabag)
#install.packages('pROC')
library(pROC)
#install.packages("MASS") #ROC 커브
library(MASS)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("pls") #시계열분석
library(pls)
# 1)데이터 불러오기
spam <- read.csv('spam.csv', header = T)
str(spam)
set.seed(9999)
# 2)데이터 정규화
normalize <- function(x) {
return ((x-min(x))/(max(x)-min(x)))
}
spam[56:57] <- normalize(spam[56:57])
# 3) train/test sets 생성
#(1)doBy train/test sets 생성
spam_train_doBy <- sampleBy(~spam, frac = 0.7, data = spam)
enrow <- rownames(spam_train_doBy)
nurow <- as.numeric(gsub('\\D','',enrow))
spam_test_doBy <- spam[-nurow,]
#(2)caret train/test sets 생성
set.seed(8888)
train_idx <- createDataPartition(spam$spam, p=0.7, list=F)
spam_train_caret <- spam[train_idx,]
spam_train_label_caret <- spam$spam[train_idx]
spam_test_caret <- spam[-train_idx,]
#(4)모델 성능 평가 지표(정확도 확인)
confusionMatrix(spam_nb_pred_doby, as.factor(spam_test_doBy$spam))
## e1071 패키지의 나이브베이즈는 약 72%의 정확도로 분류
#(4)모델 성능 평가 지표(정확도 확인)
confusionMatrix(spam_nb_pred_caret, as.factor(spam_test_caret$spam))
## caret의 나이브베이즈는 70%의 정확도로 분류
library(caret)
library(ggplot2)
library(pls)
library(randomForest)
data(economics)
str(economics)
# 내장패키지 랜포 훈련모델 작성
plsFitTime_rf <- randomForest(unemploy~. ,
data=tr,
na.action = na.omit,
ntree=100,
proximity=T)
sn <- sample(1:nrow(qq), size = nrow(qq)*0.7)
qq <- data.frame(economics)
tr <- qq[sn,]
te <- qq[-sn,]
# caret 시계열, 랜포 훈련모델 작성
myTimeControl <- trainControl(method = "timeslice",
initialWindow = 36,
horizon = 12,
fixedWindow = TRUE)
plsFitTime <- train(unemploy ~ .,
data = tr,
method = "rf",
preProc = c("center", "scale"),
trControl = myTimeControl)
plsFitTime
# 예측
pred <- predict(plsFitTime, te)
# 그래프 표시
asdf <- cbind(pred, te[,c(1,6)])
ggplot(asdf, aes(x = date, y = unemploy)) +
geom_line(aes(colour = 'real')) + geom_line(aes(x = date, y = pred, colour = 'predict')) +
scale_colour_manual(name = '측정값', values = c(real = 'red', predict = 'blue')) +
labs(title="실업자 수", x ="Date", y = "Unemploy")
sn <- sample(1:nrow(qq), size = nrow(qq)*0.7)
qq <- data.frame(economics)
tr <- qq[sn,]
te <- qq[-sn,]
# caret 시계열, 랜포 훈련모델 작성
myTimeControl <- trainControl(method = "timeslice",
initialWindow = 36,
horizon = 12,
fixedWindow = TRUE)
plsFitTime <- train(unemploy ~ .,
data = tr,
method = "rf",
preProc = c("center", "scale"),
trControl = myTimeControl)
plsFitTime
# 예측
pred <- predict(plsFitTime, te)
# 그래프 표시
asdf <- cbind(pred, te[,c(1,6)])
ggplot(asdf, aes(x = date, y = unemploy)) +
geom_line(aes(colour = 'real')) + geom_line(aes(x = date, y = pred, colour = 'predict')) +
scale_colour_manual(name = '측정값', values = c(real = 'red', predict = 'blue')) +
labs(title="실업자 수", x ="Date", y = "Unemploy")
# 내장패키지 랜포 훈련모델 작성
plsFitTime_rf <- randomForest(unemploy~. ,
data=tr,
na.action = na.omit,
ntree=100,
proximity=T)
# 내장패키지 랜포 훈련모델 작성
plsFitTime_rf <- randomForest(unemploy~. ,
data=tr,
na.action = na.omit,
ntree=100,
proximity=T)
# 예측
pred2 <- predict(plsFitTime_rf, te)
# 그래프 표시
qwer <- cbind(pred2, te[,c(1,6)])
ggplot(qwer, aes(x = date, y = unemploy)) +
geom_line(aes(colour = 'real')) + geom_line(aes(x = date, y = pred, colour = 'predict')) +
scale_colour_manual(name = '측정값', values = c(real = 'red', predict = 'blue')) +
labs(title="실업자 수", x ="Date", y = "Unemploy")
# 환경설정
rm(list=ls())
data(economics)
str(economics)
sn <- sample(1:nrow(qq), size = nrow(qq)*0.7)
qq <- data.frame(economics)
tr <- qq[sn,]
te <- qq[-sn,]
data(economics)
str(economics)
sn <- sample(1:nrow(qq), size = nrow(qq)*0.7)
qq <- data.frame(economics)
tr <- qq[sn,]
te <- qq[-sn,]
# 내장패키지 랜포 훈련모델 작성
plsFitTime_rf <- randomForest(unemploy~. ,
data=tr,
na.action = na.omit,
ntree=100,
proximity=T)
# 예측
pred2 <- predict(plsFitTime_rf, te)
# 그래프 표시
qwer <- cbind(pred2, te[,c(1,6)])
ggplot(qwer, aes(x = date, y = unemploy)) +
geom_line(aes(colour = 'real')) + geom_line(aes(x = date, y = pred, colour = 'predict')) +
scale_colour_manual(name = '측정값', values = c(real = 'red', predict = 'blue')) +
labs(title="실업자 수", x ="Date", y = "Unemploy")
plsFitTime_rf <- randomForest(unemploy~. ,
data=tr,
na.action = na.omit,
ntree=100,
proximity=T)
# 예측
pred2 <- predict(plsFitTime_rf, te)
# 그래프 표시
qwer <- cbind(pred2, te[,c(1,6)])
ggplot(qwer,
aes(x = date, y = unemploy)) +
geom_line(aes(colour = 'real')) +
geom_line(aes(x = date, y = pred, colour = 'predict')) +
scale_colour_manual(name = '측정값',
values = c(real = 'red', predict = 'blue')) +
labs(title="실업자 수",
x ="Date",
y = "Unemploy")
plot(economics$unemploy,type = "l")
myTimeControl <- trainControl(method = "timeslice",
initialWindow = 36,
horizon = 12,
fixedWindow = TRUE)
plsFitTime <- train(unemploy ~ .,
data = economics,
method = "pls",
preProc = c("center", "scale"),
trControl = myTimeControl)
plsFitTime
# 3단계 : 예측
pred <- predict(plsFitTime, economics)
asdf <- cbind(pred, economics[,c(1,6)])
ggplot(asdf, aes(x = date, y = unemploy)) +
geom_line(color = 'blue') + geom_line(aes(x = date, y = pred), color = 'red')
myTimeControl <- trainControl(method = "timeslice",
initialWindow = 36,
horizon = 12,
fixedWindow = TRUE)
plsFitTime <- train(unemploy ~ .,
data = tr,
method = "rf",
preProc = c("center", "scale"),
trControl = myTimeControl)
plsFitTime
women
treeOption1 <- ctree_control(maxdepth = 10)
abalone_tree1 <- ctree(Sex~.,
data = abalone_doBy_train,
controls = treeOption1)
plot(abalone_tree1, compress=TRUE)
#(2)예측치 생성
table(abalone_doBy_train$Sex, predict(abalone_tree1,data=abalone_doBy_train),dnn = c('Actual','Predicted'))
predict(abalone_tree1,data=abalone_doBy_train)
#(3)모형의 정확성 검정
confusionMatrix(data=abalone_doBy_test$Sex,predict(abalone_tree1,abalone_doBy_test))
# 환경설정
rm(list=ls())
library(tree)
#install.packages("doBy")
library(doBy)
#install.packages("party")
library(party) #ls("package:party")
#install.packages("caret")
library(caret) #ls("package:caret")
#install.packages("dplyr")
library(dplyr)
#install.packages("e1071") #나이브 베이즈
library(e1071)
#install.packages("randomForest")
library(randomForest)
#install.packages("data.table")
library(data.table)
#install.packages("xgboost")
library(xgboost)
#install.packages("plyr")
library(plyr)
#install.packages("car")#vif 공분산분석
library(car)
#install.packages("kernlab")
library(kernlab)
#install.packages("class")
library(class)
#install.packages("nnet")
library(nnet)
#install.packages('adabag')
library(adabag)
#install.packages('pROC')
library(pROC)
#install.packages("MASS") #ROC 커브
library(MASS)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("pls") #시계열분석
library(pls)
# spam 데이터 셋 ==============================================================
# spam데이터 설명
# 불러온 spam 데이터는 4601개의 이메일에서 등장하는 단어의 종류와 관련된 58개의 변수로 구성되어있다.
# 58개의 변수 중 처음 48개 변수(A.1~A.48)은 총 단어수 대비 해당 단어의 출현비율을 나타내며,
# 6개 변수(A.49~A.54)는 총 문자수 대비 특정 문자의 출현비율을 나타내며,
# 3개 변수(A.55~A.57)은 연속되는 대문자 철차의 평균길이, 최대길이, 대문자의 총수를 나타낸다.
# 마지막 변수(spam)스팸 메일의 여부를 타나냅니다.
# 즉 spam 변수가 종속변수가 되며 나머지 A.1~57 변수가 예측변수가 된다..
# 결측값은 없으며 전체에서 스팸메일은 1813개다.
## 1.데이터 전처리 ============================================================
# 1)데이터 불러오기
spam <- read.csv('spam.csv', header = T)
str(spam)
set.seed(9999)
# 2)데이터 정규화
normalize <- function(x) {
return ((x-min(x))/(max(x)-min(x)))
}
spam[56:57] <- normalize(spam[56:57])
# 3) train/test sets 생성
#(1)doBy train/test sets 생성
spam_train_doBy <- sampleBy(~spam, frac = 0.7, data = spam)
enrow <- rownames(spam_train_doBy)
nurow <- as.numeric(gsub('\\D','',enrow))
spam_test_doBy <- spam[-nurow,]
#(2)caret train/test sets 생성
set.seed(8888)
train_idx <- createDataPartition(spam$spam, p=0.7, list=F)
spam_train_caret <- spam[train_idx,]
spam_train_label_caret <- spam$spam[train_idx]
spam_test_caret <- spam[-train_idx,]
spam_nb_doby <- naiveBayes(spam ~ .,
data = spam_train_doBy,
laplace = 1)
spam_nb_doby
#(2)예측 분류 결과 생성
spam_nb_pred_doby <- predict(spam_nb_doby, newdata = spam_test_doBy, type = 'class')
#(3)나이브베이즈 적용 분류 결과 도출
table(spam_nb_pred_doby, spam_test_doBy$spam)
#(4)모델 성능 평가 지표(정확도 확인)
confusionMatrix(spam_nb_pred_doby, as.factor(spam_test_doBy$spam))
#(1)SVM 학습 모델 생성
spam_svm_doBy <- svm(factor(spam) ~ .,
data = spam_train_doBy,
gamma = 0.5,
cost = 4)
spam_svm_doBy
#(2)예측 분류 결과 생성
spam_svm_pred_doBy <- predict(spam_svm_doBy, newdata = spam_test_doBy)
spam_svm_pred_doBy
#(3)모델 성능 평가 지표(정확도 확인)
confusionMatrix(spam_svm_pred_doBy, factor(spam_test_doBy$spam))
# e1071패키지의 SVM은 정확도(0.8101). 즉, 약 81% 정확도로 분류하였다.
# 라이브러리
#install.packages("tree")
library(tree)
#install.packages("doBy")
library(doBy)
#install.packages("party")
library(party) #ls("package:party")
#install.packages("caret")
library(caret) #ls("package:caret")
#install.packages("dplyr")
library(dplyr)
#install.packages("e1071") #나이브 베이즈
library(e1071)
#install.packages("randomForest")
library(randomForest)
#install.packages("data.table")
library(data.table)
#install.packages("xgboost")
library(xgboost)
#install.packages("plyr")
library(plyr)
#install.packages("car")#vif 공분산분석
library(car)
#install.packages("kernlab")
library(kernlab)
#install.packages("class")
library(class)
#install.packages("nnet")
library(nnet)
#install.packages('adabag')
library(adabag)
#install.packages('pROC')
library(pROC)
#install.packages("MASS") #ROC 커브
library(MASS)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("pls") #시계열분석
library(pls)
data3 <- iris
# 2)데이터 추출/자료형 변환
# 라벨링
iris_label <- ifelse(data3$Species == 'setosa', 0,
ifelse(data3$Species == 'versicolor', 1,2))
table(iris_label)
data3$label <- iris_label
sapply(data3,class)
# 3) train/test sets 생
data3 <- iris
# 2)데이터 추출/자료형 변환
# 라벨링
iris_label <- ifelse(data3$Species == 'setosa', 0,
ifelse(data3$Species == 'versicolor', 1,2))
table(iris_label)
data3$label <- iris_label
sapply(data3,class)
# 3) train/test sets 생성
#(1)doBy train/test sets 생성
set.seed(1111)
iris_doBy_train <- sampleBy(~Species, frac=0.7, data=data3) #전복의 성별을 기준으로 동일한 비율로 나눔
iris_doBy_test <- sampleBy(~Species, frac=0.3, data=data3)
iris_doBy_train_mat <- as.matrix(iris_doBy_train[-c(5:6)])
iris_doBy_train_lab <- iris_doBy_train$label
dim(iris_doBy_train_mat)
length(iris_doBy_train_lab)
#(2)caret train/test sets 생성
set.seed(1000)
iris_intrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
iris_caret_train <-iris[iris_intrain, ]
iris_caret_test <-iris[-iris_intrain, ]
table(iris_caret_train$Species)
table(iris_caret_test$Species)
## 2.분석 =====================================================================
### 상황1 ####
# 여러가지 기법을 활용하여 붓꽃의 종류를 분류하고 가장 정확한 분류모델을 가려낸다.
#### 1)xgboost ####
#xgBoost 패키지
# 학습모델 생성
iris_doBy_dtrain <- xgb.DMatrix(data = iris_doBy_train_mat,
label = iris_doBy_train_lab)
iris_doBy_xgb_model <- xgboost(data = iris_doBy_dtrain, max_depth = 2, eta = 1,
nthread = 2, nrounds = 2,
objective = "multi:softmax",
num_class = 3,
verbose = 0)
iris_doBy_xgb_model
# 모델 평가
iris_doBy_test_mat <- as.matrix(iris_doBy_test[-c(5:6)])
iris_doBy_test_lab <- iris_doBy_test$label
doBy_pred_iris <- predict(iris_doBy_xgb_model, iris_doBy_test_mat)
doBy_pred_iris
table(doBy_pred_iris, iris_doBy_test_lab)
(15+15+15) / length(iris_doBy_test_lab)
# 주요변수 확인
importance_matrix <- xgb.importance(colnames(iris_doBy_train_mat),
model = iris_doBy_xgb_model)
importance_matrix
xgb.plot.importance(importance_matrix)
#caret 패키지
# 데이터 분할
set.seed(123)
idx = createDataPartition(data3$Species, list=F, p=0.7)
Train = df[ idx,]
Train = df[idx,]
Train = data3[idx,]
Test  = data3[-idx,]
train.data  = as.matrix(Train[, names(data3)!="Species"])
test.data   = as.matrix(Test[ , names(data3)!="Species"])
train.label = as.integer(Train$Species) - 1 # 0기반
test.label  = as.integer(Test$Species) - 1 # 0기반
# 모델 생성
dtrain = xgb.DMatrix(data=train.data, label=train.label)
dtest  = xgb.DMatrix(data=test.data , label=test.label )
watchlist = list(train=dtrain, eval=dtest)
param = list(max_depth=2, eta=1, verbose=0, nthread=2,
objective="multi:softprob", eval_metric="mlogloss", num_class=3)
model = xgb.train(param, dtrain, nrounds=2, watchlist)
# 테스트
pred = as.data.frame(predict(model,test.data,reshape=T))
names = levels(data3$Species)
colnames(pred) = names
pred$prediction = apply(pred,1,function(x) names[which.max(x)])
pred$class = Test$Species
pred
table(pred$prediction, pred$class)
#정분류율
sum(pred$prediction==pred$class)/nrow(pred)
